{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\n\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\n\n\ntrain_on_gpu = torch.cuda.is_available()\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-25T11:44:54.410044Z","iopub.execute_input":"2022-03-25T11:44:54.410550Z","iopub.status.idle":"2022-03-25T11:44:56.065822Z","shell.execute_reply.started":"2022-03-25T11:44:54.410377Z","shell.execute_reply":"2022-03-25T11:44:56.064858Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/asl-alphabet/'\ntrain_dir = os.path.join(data_dir, 'asl_alphabet_train/asl_alphabet_train/')","metadata":{"execution":{"iopub.status.busy":"2022-03-25T11:44:56.067928Z","iopub.execute_input":"2022-03-25T11:44:56.068552Z","iopub.status.idle":"2022-03-25T11:44:56.073532Z","shell.execute_reply.started":"2022-03-25T11:44:56.068475Z","shell.execute_reply":"2022-03-25T11:44:56.072402Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# VGG-16 Takes 224x224 images as input, so we resize all of them\ndata_transform = transforms.Compose([transforms.RandomResizedCrop(224), \n                                      transforms.ToTensor()])\n\ntrain_data = datasets.ImageFolder(train_dir, transform=data_transform)\n\nprint('Num training images: ', len(train_data))","metadata":{"execution":{"iopub.status.busy":"2022-03-25T11:44:56.075080Z","iopub.execute_input":"2022-03-25T11:44:56.075647Z","iopub.status.idle":"2022-03-25T11:46:30.289924Z","shell.execute_reply.started":"2022-03-25T11:44:56.075602Z","shell.execute_reply":"2022-03-25T11:46:30.289027Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Num training images:  87000\n","output_type":"stream"}]},{"cell_type":"code","source":"classes = train_data.class_to_idx","metadata":{"execution":{"iopub.status.busy":"2022-03-25T11:46:30.292571Z","iopub.execute_input":"2022-03-25T11:46:30.293635Z","iopub.status.idle":"2022-03-25T11:46:30.298254Z","shell.execute_reply.started":"2022-03-25T11:46:30.293590Z","shell.execute_reply":"2022-03-25T11:46:30.297520Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T11:46:30.310956Z","iopub.execute_input":"2022-03-25T11:46:30.311654Z","iopub.status.idle":"2022-03-25T11:46:30.316128Z","shell.execute_reply.started":"2022-03-25T11:46:30.311614Z","shell.execute_reply":"2022-03-25T11:46:30.315351Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"vgg16 = models.vgg16(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T11:46:30.319223Z","iopub.execute_input":"2022-03-25T11:46:30.319648Z","iopub.status.idle":"2022-03-25T11:46:42.429526Z","shell.execute_reply.started":"2022-03-25T11:46:30.319612Z","shell.execute_reply":"2022-03-25T11:46:42.428741Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/528M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df41a7f1fd9e4a41923c20b6ee592cb5"}},"metadata":{}}]},{"cell_type":"code","source":"# Freeze training for all \"features\" layers\nfor param in vgg16.features.parameters():\n    param.requires_grad = False  ","metadata":{"execution":{"iopub.status.busy":"2022-03-25T11:46:42.431016Z","iopub.execute_input":"2022-03-25T11:46:42.431303Z","iopub.status.idle":"2022-03-25T11:46:42.436303Z","shell.execute_reply.started":"2022-03-25T11:46:42.431267Z","shell.execute_reply":"2022-03-25T11:46:42.435096Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nvgg16.classifier[6] = nn.Linear(in_features=vgg16.classifier[6].in_features, out_features=29, bias=True)\n\n\n# after completing your model, if GPU is available, move the model to GPU\nif train_on_gpu:\n    vgg16.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T11:46:42.437760Z","iopub.execute_input":"2022-03-25T11:46:42.437999Z","iopub.status.idle":"2022-03-25T11:46:45.634744Z","shell.execute_reply.started":"2022-03-25T11:46:42.437967Z","shell.execute_reply":"2022-03-25T11:46:45.632784Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\n# specify loss function (categorical cross-entropy)\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer (stochastic gradient descent) and learning rate = 0.001\noptimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-25T11:46:45.641872Z","iopub.execute_input":"2022-03-25T11:46:45.642446Z","iopub.status.idle":"2022-03-25T11:46:45.656436Z","shell.execute_reply.started":"2022-03-25T11:46:45.642400Z","shell.execute_reply":"2022-03-25T11:46:45.655814Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"n_epochs = 20\n\nfor epoch in range(1, n_epochs+1):\n    train_loss = 0.0\n    for batch_i, (data, target) in enumerate(train_loader):\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        optimizer.zero_grad()\n        output = vgg16(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        \n        if batch_i % 200 == 199:    # print training loss \n            print('Epoch %d, Batch %d loss: %.16f' %\n                  (epoch, batch_i + 1, train_loss / 200))\n            train_loss = 0.0","metadata":{"execution":{"iopub.status.busy":"2022-03-25T11:46:45.657590Z","iopub.execute_input":"2022-03-25T11:46:45.658330Z","iopub.status.idle":"2022-03-25T14:48:45.831551Z","shell.execute_reply.started":"2022-03-25T11:46:45.658293Z","shell.execute_reply":"2022-03-25T14:48:45.830726Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1, Batch 200 loss: 3.3035264575481413\nEpoch 1, Batch 400 loss: 3.1065577018260955\nEpoch 1, Batch 600 loss: 2.9099041104316710\nEpoch 1, Batch 800 loss: 2.7124437594413759\nEpoch 1, Batch 1000 loss: 2.5316750633716585\nEpoch 1, Batch 1200 loss: 2.3602901434898378\nEpoch 2, Batch 200 loss: 2.1340176939964293\nEpoch 2, Batch 400 loss: 2.0570934367179872\nEpoch 2, Batch 600 loss: 1.9674622452259063\nEpoch 2, Batch 800 loss: 1.8895116460323333\nEpoch 2, Batch 1000 loss: 1.8530072426795960\nEpoch 2, Batch 1200 loss: 1.7706041193008424\nEpoch 3, Batch 200 loss: 1.6836629289388656\nEpoch 3, Batch 400 loss: 1.6340192282199859\nEpoch 3, Batch 600 loss: 1.6219015550613403\nEpoch 3, Batch 800 loss: 1.5662782645225526\nEpoch 3, Batch 1000 loss: 1.5261663013696671\nEpoch 3, Batch 1200 loss: 1.5304266858100890\nEpoch 4, Batch 200 loss: 1.4760438984632491\nEpoch 4, Batch 400 loss: 1.4775691062211991\nEpoch 4, Batch 600 loss: 1.4306568965315818\nEpoch 4, Batch 800 loss: 1.4166228652000428\nEpoch 4, Batch 1000 loss: 1.4021675759553909\nEpoch 4, Batch 1200 loss: 1.3802762255072594\nEpoch 5, Batch 200 loss: 1.3364038103818894\nEpoch 5, Batch 400 loss: 1.3197029691934585\nEpoch 5, Batch 600 loss: 1.3159735050797463\nEpoch 5, Batch 800 loss: 1.3107964926958084\nEpoch 5, Batch 1000 loss: 1.3059334662556648\nEpoch 5, Batch 1200 loss: 1.2940110695362090\nEpoch 6, Batch 200 loss: 1.2632084983587264\nEpoch 6, Batch 400 loss: 1.2601914405822754\nEpoch 6, Batch 600 loss: 1.2331348243355751\nEpoch 6, Batch 800 loss: 1.2287428322434426\nEpoch 6, Batch 1000 loss: 1.2397681933641433\nEpoch 6, Batch 1200 loss: 1.2011811158061028\nEpoch 7, Batch 200 loss: 1.2157647180557252\nEpoch 7, Batch 400 loss: 1.1830713737010956\nEpoch 7, Batch 600 loss: 1.1780190402269364\nEpoch 7, Batch 800 loss: 1.1811969327926635\nEpoch 7, Batch 1000 loss: 1.1657968741655349\nEpoch 8, Batch 200 loss: 1.1516276496648787\nEpoch 8, Batch 400 loss: 1.1371258497238159\nEpoch 8, Batch 600 loss: 1.1331709423661231\nEpoch 8, Batch 800 loss: 1.1310629928112030\nEpoch 8, Batch 1000 loss: 1.1131755957007408\nEpoch 8, Batch 1200 loss: 1.1154288581013680\nEpoch 9, Batch 200 loss: 1.0928088572621346\nEpoch 9, Batch 400 loss: 1.1090290579199791\nEpoch 9, Batch 600 loss: 1.0979627409577370\nEpoch 9, Batch 800 loss: 1.0864348468184470\nEpoch 9, Batch 1000 loss: 1.0979725536704064\nEpoch 9, Batch 1200 loss: 1.0826627340912820\nEpoch 10, Batch 200 loss: 1.0708777710795403\nEpoch 10, Batch 400 loss: 1.0638526812195779\nEpoch 10, Batch 600 loss: 1.0362115707993507\nEpoch 10, Batch 800 loss: 1.0481978571414947\nEpoch 10, Batch 1000 loss: 1.0416386944055558\nEpoch 10, Batch 1200 loss: 1.0267808064818382\nEpoch 11, Batch 200 loss: 1.0468870419263840\nEpoch 11, Batch 400 loss: 1.0348880273103713\nEpoch 11, Batch 600 loss: 1.0218640080094337\nEpoch 11, Batch 800 loss: 1.0129837822914123\nEpoch 11, Batch 1000 loss: 1.0187666314840316\nEpoch 11, Batch 1200 loss: 1.0303188526630402\nEpoch 12, Batch 200 loss: 1.0156825868785382\nEpoch 12, Batch 400 loss: 0.9836147591471672\nEpoch 12, Batch 600 loss: 1.0008655929565429\nEpoch 12, Batch 800 loss: 1.0020020681619644\nEpoch 12, Batch 1000 loss: 0.9944454681873321\nEpoch 12, Batch 1200 loss: 0.9759287735819817\nEpoch 13, Batch 200 loss: 0.9824876555800438\nEpoch 13, Batch 400 loss: 0.9891674995422364\nEpoch 13, Batch 600 loss: 0.9784309579432011\nEpoch 13, Batch 800 loss: 0.9669688525795936\nEpoch 13, Batch 1000 loss: 0.9814805442094803\nEpoch 13, Batch 1200 loss: 0.9746011528372764\nEpoch 14, Batch 200 loss: 0.9500489801168441\nEpoch 14, Batch 400 loss: 0.9600908276438713\nEpoch 14, Batch 600 loss: 0.9349391023814678\nEpoch 14, Batch 800 loss: 0.9675372833013535\nEpoch 14, Batch 1000 loss: 0.9461718922853470\nEpoch 14, Batch 1200 loss: 0.9273316085338592\nEpoch 15, Batch 200 loss: 0.9428145074844361\nEpoch 15, Batch 400 loss: 0.9280683955550194\nEpoch 15, Batch 600 loss: 0.9296583962440491\nEpoch 15, Batch 800 loss: 0.9377884307503700\nEpoch 15, Batch 1000 loss: 0.9304838445782662\nEpoch 15, Batch 1200 loss: 0.9369971236586571\nEpoch 16, Batch 200 loss: 0.9025736653804779\nEpoch 16, Batch 400 loss: 0.9083849591016769\nEpoch 16, Batch 600 loss: 0.9196401658654213\nEpoch 16, Batch 800 loss: 0.9193193072080612\nEpoch 16, Batch 1000 loss: 0.9026551285386085\nEpoch 16, Batch 1200 loss: 0.8867767947912216\nEpoch 17, Batch 200 loss: 0.9186123740673066\nEpoch 17, Batch 400 loss: 0.8945750731229782\nEpoch 17, Batch 600 loss: 0.9011556670069695\nEpoch 17, Batch 800 loss: 0.8934565052390099\nEpoch 17, Batch 1000 loss: 0.8976412430405617\nEpoch 17, Batch 1200 loss: 0.8895531824231148\nEpoch 18, Batch 200 loss: 0.9038074573874474\nEpoch 18, Batch 400 loss: 0.8606302431225776\nEpoch 18, Batch 600 loss: 0.8855777013301850\nEpoch 18, Batch 800 loss: 0.8608345443010330\nEpoch 18, Batch 1000 loss: 0.8779774972796440\nEpoch 18, Batch 1200 loss: 0.8693119385838508\nEpoch 19, Batch 200 loss: 0.8645060777664184\nEpoch 19, Batch 400 loss: 0.8757874724268914\nEpoch 19, Batch 600 loss: 0.8567469431459904\nEpoch 19, Batch 800 loss: 0.8648921743035316\nEpoch 19, Batch 1000 loss: 0.8595536074042320\nEpoch 19, Batch 1200 loss: 0.8652719426155090\nEpoch 20, Batch 200 loss: 0.8322731770575047\nEpoch 20, Batch 400 loss: 0.8599931466579437\nEpoch 20, Batch 600 loss: 0.8436404471099377\nEpoch 20, Batch 800 loss: 0.8483914682269096\nEpoch 20, Batch 1000 loss: 0.8324723911285400\nEpoch 20, Batch 1200 loss: 0.8502910499274731\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(vgg16.state_dict(), './ASL20')","metadata":{"execution":{"iopub.status.busy":"2022-03-25T14:48:45.832774Z","iopub.execute_input":"2022-03-25T14:48:45.833020Z","iopub.status.idle":"2022-03-25T14:48:47.155888Z","shell.execute_reply.started":"2022-03-25T14:48:45.832987Z","shell.execute_reply":"2022-03-25T14:48:47.155121Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import json\nwith open('./classes.json', 'w') as fp:\n    json.dump(classes, fp)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T14:48:47.157487Z","iopub.execute_input":"2022-03-25T14:48:47.157776Z","iopub.status.idle":"2022-03-25T14:48:47.162555Z","shell.execute_reply.started":"2022-03-25T14:48:47.157738Z","shell.execute_reply":"2022-03-25T14:48:47.161871Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\nidx_to_class = {value:key for key, value in classes.items()} ","metadata":{"execution":{"iopub.status.busy":"2022-03-25T14:54:41.467380Z","iopub.execute_input":"2022-03-25T14:54:41.467943Z","iopub.status.idle":"2022-03-25T14:54:41.472088Z","shell.execute_reply.started":"2022-03-25T14:54:41.467905Z","shell.execute_reply":"2022-03-25T14:54:41.471287Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import os\ncorrect = 0\ntest_files = os.listdir('../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/')\nvgg16.eval()\nfor file in test_files:\n    label = file.strip('_')[0]\n    path = os.path.join('../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/',file)\n    img = Image.open(path)\n    img_tensor = data_transform(img).to('cuda').unsqueeze(0)\n    output = vgg16(img_tensor)\n    _, index = torch.max(output, 1)\n    index = index.cpu().tolist()\n    if label == idx_to_class[index[0]]:\n        correct += 1\nprint('Test Accuracy : ', round(correct/len(test_files)*100, 2), '%')","metadata":{"execution":{"iopub.status.busy":"2022-03-25T15:08:59.024136Z","iopub.execute_input":"2022-03-25T15:08:59.024612Z","iopub.status.idle":"2022-03-25T15:08:59.258973Z","shell.execute_reply.started":"2022-03-25T15:08:59.024574Z","shell.execute_reply":"2022-03-25T15:08:59.258156Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Test Accuracy :  82.14 %\n","output_type":"stream"}]},{"cell_type":"code","source":"# def image_loader(loader, image_name):\n#     image = Image.open(image_name)\n#     image = loader(image).float()\n#     image = torch.tensor(image, requires_grad=True).cuda()\n#     image = image.unsqueeze(0)\n#     return image\n\n\n# # model_ft = models.resnet152(pretrained=True)\n# # model_ft.eval()\n\n\n# FILENAME = '../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/J_test.jpg'\n# print( np.argmax(vgg16(image_loader(data_transform, FILENAME)).cpu().detach().numpy()))\n# # vgg16(image_loader(data_transform, FILENAME))","metadata":{"execution":{"iopub.status.busy":"2022-03-25T14:48:47.164061Z","iopub.execute_input":"2022-03-25T14:48:47.164635Z","iopub.status.idle":"2022-03-25T14:48:47.172736Z","shell.execute_reply.started":"2022-03-25T14:48:47.164594Z","shell.execute_reply":"2022-03-25T14:48:47.171702Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# vgg16.eval()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T14:48:47.174553Z","iopub.execute_input":"2022-03-25T14:48:47.174832Z","iopub.status.idle":"2022-03-25T14:48:47.181920Z","shell.execute_reply.started":"2022-03-25T14:48:47.174787Z","shell.execute_reply":"2022-03-25T14:48:47.180801Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# for batch_i, (idx, data, target) in enumerate(test_loader):\n#     print(idx, data, target)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T14:48:47.183847Z","iopub.execute_input":"2022-03-25T14:48:47.184171Z","iopub.status.idle":"2022-03-25T14:48:47.190819Z","shell.execute_reply.started":"2022-03-25T14:48:47.184128Z","shell.execute_reply":"2022-03-25T14:48:47.189589Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# out = []\n# import sys\n# for batch_i, (idx, data) in enumerate(test_loader):\n#     # move tensors to GPU if CUDA is available\n#     if train_on_gpu:\n#         data = data.cuda()\n#     output = vgg16(data)\n#     _, index = torch.max(output, 1)\n#     idx = idx.tolist()\n#     index = index.cpu().tolist()\n#     out.append((idx, index))","metadata":{"execution":{"iopub.status.busy":"2022-03-25T14:48:47.192708Z","iopub.execute_input":"2022-03-25T14:48:47.193307Z","iopub.status.idle":"2022-03-25T14:48:47.199360Z","shell.execute_reply.started":"2022-03-25T14:48:47.193267Z","shell.execute_reply":"2022-03-25T14:48:47.198349Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# from torchvision import models, transforms\n# import torch\n\n# train_on_gpu = torch.cuda.is_available()\n\n\n# data_transform = transforms.Compose([transforms.RandomResizedCrop(224), \n#                                       transforms.ToTensor()])\n\n\n# vgg16 = models.vgg16(pretrained=False)\n# vgg16.classifier[6] = nn.Linear(in_features=4096, out_features=29, bias=True)\n\n# if train_on_gpu:\n#     vgg16.cuda()\n    \n# vgg16.load_state_dict(torch.load('PATH'))\n# vgg16.eval()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T14:48:47.201214Z","iopub.execute_input":"2022-03-25T14:48:47.201550Z","iopub.status.idle":"2022-03-25T14:48:47.211610Z","shell.execute_reply.started":"2022-03-25T14:48:47.201515Z","shell.execute_reply":"2022-03-25T14:48:47.210807Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# import os\n# import pandas as pd\n# testfiles = os.listdir('../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/')\n\n# def getclass(str_: str):\n#     return str_.split('_')[0]\n# classes = list(map(getclass, testfiles))\n\n# outDF = pd.DataFrame(data = zip(testfiles, classes), columns = ['filename', 'label'])","metadata":{"execution":{"iopub.status.busy":"2022-03-25T14:48:47.212917Z","iopub.execute_input":"2022-03-25T14:48:47.213438Z","iopub.status.idle":"2022-03-25T14:48:47.222895Z","shell.execute_reply.started":"2022-03-25T14:48:47.213400Z","shell.execute_reply":"2022-03-25T14:48:47.222036Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# from torch.utils.data import Dataset\n\n# class TestDataset(Dataset):\n#     def __init__(self, data_frame, root_dir, transform=None):\n#         self.data_frame = data_frame\n#         self.root_dir = root_dir\n#         self.transform = transform\n    \n#     def __len__(self):\n#         return len(self.data_frame)\n    \n#     def __getitem__(self, idx):\n#         if torch.is_tensor(idx):\n#             idx = idx.tolist()\n        \n#         img_name = os.path.join(self.root_dir, self.data_frame.iloc[idx, 0])\n#         image = Image.open(img_name)\n# #         label = self.data_frame.iloc[idx, -1]\n        \n#         if self.transform:\n#             image = self.transform(image)\n    \n#         return (idx\n#                 , image\n# #                 , label\n#                )\n\n# test_data  = TestDataset(root_dir = test_dir, data_frame = outDF, transform=data_transform)\n# test_loader = torch.utils.data.DataLoader(test_data , batch_size=20, shuffle=False)\n# print('Num Test images: ', len(test_data))","metadata":{"execution":{"iopub.status.busy":"2022-03-25T14:48:47.224209Z","iopub.execute_input":"2022-03-25T14:48:47.224789Z","iopub.status.idle":"2022-03-25T14:48:47.232132Z","shell.execute_reply.started":"2022-03-25T14:48:47.224704Z","shell.execute_reply":"2022-03-25T14:48:47.231255Z"},"trusted":true},"execution_count":19,"outputs":[]}]}