{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Get_Data_From_COI_end.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRfIR1c33arw+ZetFY4m+u"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ViHQuY9N0Ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBTMHt8nM-2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "url_list=pd.read_csv('output_links.csv',header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ2LWvpU7KCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This block of code is used to extract contents of end pages into two values \"title\"=Name of Article and \"page_text\"=All the contents of the page\n",
        "final_list=[('title','paragraphs')]\n",
        "for url in url_list:\n",
        "  page2 = urllib.request.urlopen(url)\n",
        "  soup2 = BeautifulSoup(page2, 'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "  content_div=soup2.find_all('div', attrs={'class': \"title-block center-block element-spacer-bottom-10\"})\n",
        "  content=[]\n",
        "  for value in content_div:\n",
        "    content.append(value.getText().replace(u'\\xa0', u'').split('\\n'))\n",
        "  if len(content)!=0:\n",
        "    content=content[0]\n",
        "  while(\"\" in content) : \n",
        "      content.remove(\"\") \n",
        "  text=''\n",
        "  for string in content:\n",
        "    text=text+string\n",
        "  content_div=soup2.find_all('div', attrs={'class': \"banner-text-wrapper\"})\n",
        "  content=[]\n",
        "  for value in content_div:\n",
        "    content.append(value.getText().replace(u'\\xa0', u'').split('\\n'))\n",
        "  if len(content)!=0:\n",
        "    content=content[0]\n",
        "  while(\"\" in content) : \n",
        "      content.remove(\"\") \n",
        "  for string in content:\n",
        "    text=text+' '+string\n",
        "  title=text;\n",
        "\n",
        "\n",
        "  content_div=soup2.find_all('div', attrs={'class': 'description-wrapper'})\n",
        "  content=[]\n",
        "  for value in content_div:\n",
        "    content.append(value.getText().replace(u'\\xa0', u'').split('\\n'))\n",
        "  if len(content)!=0:\n",
        "    content=content[0]\n",
        "  while(\"\" in content) : \n",
        "      content.remove(\"\") \n",
        "  text=title\n",
        "  for string in content:\n",
        "    text=text+string\n",
        "  page_text=text;\n",
        "\n",
        "  content_div=soup2.find_all('div', attrs={'class': 'summary-block'})\n",
        "  content=[]\n",
        "  for value in content_div:\n",
        "    content.append(value.getText().replace(u'\\xa0', u'').split('\\n'))\n",
        "  if len(content)!=0:\n",
        "    content=content[0]\n",
        "  while(\"\" in content) : \n",
        "      content.remove(\"\") \n",
        "  for string in content:\n",
        "    text=text+string\n",
        "  page_text=text;\n",
        "\n",
        "  content_div=soup2.find_all('div', attrs={'class': 'description-content'})\n",
        "  content=[]\n",
        "  for value in content_div:\n",
        "    content.append(value.getText().replace(u'\\xa0', u'').split('\\n'))\n",
        "  if len(content)!=0:\n",
        "    content=content[0]\n",
        "  while(\"\" in content) : \n",
        "      content.remove(\"\") \n",
        "  for string in content:\n",
        "    text=text+string\n",
        "  page_text=text;\n",
        "  \n",
        "  final_list.append((title,page_text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOqpcOVyRQ7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe=pd.DataFrame(final_list)\n",
        "dataframe=dataframe.iloc[1:,:]\n",
        "dataframe.columns=['title','paragraphs']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XplrjercR3Su",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4ef1575c-8374-4872-dde6-4c99382650cb"
      },
      "source": [
        "dataframe.to_csv('constitution_of_india.csv')\n",
        "from google.colab import files\n",
        "files.download(\"constitution_of_india.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f9088b9a-2e97-4506-8f1e-828d432326fc\", \"constitution_of_india.csv\", 938854)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}