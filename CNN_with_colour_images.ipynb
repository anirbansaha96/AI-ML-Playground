{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_with_colour_images.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMthWHF2IZUvaAnjN6bvyBx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDRK5MMHz4Rn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "59834bdc-b19f-4f0f-a6e1-f33be44a7f59"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)\n",
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "BATCH_SIZE = 100  # Number of training examples to process before updating our models variables\n",
        "IMG_SHAPE  = 150  # Our training data consists of images with width of 150 pixels and height of 150 pixels\n",
        "train_image_generator      = ImageDataGenerator(rescale=1./255)  # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)  # Generator for our validation data\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "                                                           class_mode='binary')\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              shuffle=False,\n",
        "                                                              target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "                                                              class_mode='binary')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 1s 0us/step\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sAvYRj80ysi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "870b58e5-da0c-4b98-bb37-e8f78cac8c78"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "EPOCHS = 10\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 10s 491ms/step - loss: 0.7154 - accuracy: 0.4960 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 10s 491ms/step - loss: 0.6924 - accuracy: 0.5015 - val_loss: 0.6875 - val_accuracy: 0.5070\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 10s 487ms/step - loss: 0.6887 - accuracy: 0.5450 - val_loss: 0.6798 - val_accuracy: 0.5130\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 10s 489ms/step - loss: 0.6676 - accuracy: 0.5985 - val_loss: 0.6392 - val_accuracy: 0.6170\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 10s 496ms/step - loss: 0.6339 - accuracy: 0.6280 - val_loss: 0.6287 - val_accuracy: 0.6470\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 10s 504ms/step - loss: 0.5983 - accuracy: 0.6715 - val_loss: 0.6038 - val_accuracy: 0.7020\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 10s 495ms/step - loss: 0.5784 - accuracy: 0.6980 - val_loss: 0.6013 - val_accuracy: 0.6740\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 10s 500ms/step - loss: 0.5533 - accuracy: 0.7090 - val_loss: 0.5833 - val_accuracy: 0.6990\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 10s 493ms/step - loss: 0.5126 - accuracy: 0.7455 - val_loss: 0.5682 - val_accuracy: 0.6990\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 10s 494ms/step - loss: 0.4787 - accuracy: 0.7700 - val_loss: 0.5707 - val_accuracy: 0.7120\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}